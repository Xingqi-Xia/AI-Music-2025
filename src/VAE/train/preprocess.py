import os
import glob
import numpy as np
import miditoolkit
import torch
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
INPUT_DIR = "./midi_dataset_local/data"       # åˆšæ‰ä¸‹è½½çš„ MIDI æ–‡ä»¶å¤¹
OUTPUT_FILE = "classical_dataset.pt" # ä¿å­˜çš„ PyTorch æ•°æ®é›†æ–‡ä»¶
SEQ_LEN = 32                         # åºåˆ—é•¿åº¦ (4å°èŠ‚ * 8ä¸ªéŸ³ç¬¦/å°èŠ‚)
QUANTIZATION = 8                     # 1/8 éŸ³ç¬¦é‡åŒ–
MIN_NOTE_PITCH = 21                  # é’¢ç´æœ€ä½éŸ³ (A0)
MAX_NOTE_PITCH = 108                 # é’¢ç´æœ€é«˜éŸ³ (C8)
AUGMENT_RANGE = range(-6, 6)         # ç§»è°ƒå¢å¼ºèŒƒå›´
NUM_WORKERS = 32                     # CPU å¹¶è¡Œæ ¸å¿ƒæ•° (æ ¹æ®ä½ çš„æœåŠ¡å™¨è°ƒæ•´)
# ===========================================

def encode_segment(notes, ticks_per_grid, segment_start_tick):
    """
    å°†ä¸€æ®µ MIDI éŸ³ç¬¦åˆ—è¡¨è½¬æ¢ä¸º [SEQ_LEN] çš„æ•´æ•°å‘é‡
    ç¼–ç è§„åˆ™: 0=Rest, 1=Hold, p+2=Pitch
    """
    # åˆå§‹åŒ–ä¸ºä¼‘æ­¢ç¬¦
    grid = np.zeros(SEQ_LEN, dtype=int)
    
    # ç­–ç•¥ï¼šHighest Pitch Priority (é«˜éŸ³ä¼˜å…ˆä½œä¸ºæ—‹å¾‹)
    # æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ array æ¥è®°å½•æ¯ä¸ªæ ¼å­çš„ (status, pitch)
    # status: 0=rest, 1=hold, 2=onset
    
    # ç”¨å­—å…¸è®°å½•æ¯ä¸ª grid index ä¸Šå‡ºç°çš„éŸ³ç¬¦ä¿¡æ¯ï¼š{index: (pitch, is_onset)}
    # å¦‚æœåŒä¸€æ ¼æœ‰å¤šä¸ªéŸ³ï¼Œä¿ç•™ pitch æœ€å¤§çš„
    temp_grid = {}

    segment_end_tick = segment_start_tick + SEQ_LEN * ticks_per_grid

    for note in notes:
        # æ£€æŸ¥éŸ³ç¬¦æ˜¯å¦åœ¨è¿™ä¸ªç‰‡æ®µçš„æ—¶é—´èŒƒå›´å†…
        if note.end < segment_start_tick or note.start >= segment_end_tick:
            continue
            
        # è®¡ç®—éŸ³ç¬¦åœ¨ç½‘æ ¼ä¸­çš„ç›¸å¯¹ä½ç½®
        # Quantize start
        rel_start = max(0, note.start - segment_start_tick)
        start_idx = int(round(rel_start / ticks_per_grid))
        
        # Quantize end
        rel_end = min(segment_end_tick - segment_start_tick, note.end - segment_start_tick)
        end_idx = int(round(rel_end / ticks_per_grid))
        
        # ä¿®æ­£è¾¹ç•Œ
        if start_idx >= SEQ_LEN: continue
        end_idx = min(end_idx, SEQ_LEN)
        if start_idx == end_idx: continue # éŸ³ç¬¦å¤ªçŸ­ï¼Œå¿½ç•¥

        # å¡«å……ç½‘æ ¼
        for i in range(start_idx, end_idx):
            is_onset = (i == start_idx)
            current_pitch = note.pitch
            
            # å†²çªå¤„ç†ï¼šä¿ç•™é«˜éŸ³
            if i not in temp_grid:
                temp_grid[i] = (current_pitch, is_onset)
            else:
                prev_pitch, prev_onset = temp_grid[i]
                if current_pitch > prev_pitch:
                    temp_grid[i] = (current_pitch, is_onset)

    # å°† temp_grid è½¬æ¢ä¸ºæœ€ç»ˆçš„ encoding
    for i in range(SEQ_LEN):
        if i in temp_grid:
            pitch, is_onset = temp_grid[i]
            if is_onset:
                grid[i] = pitch + 2 # Note On
            else:
                grid[i] = 1         # Note Hold
        else:
            grid[i] = 0             # Rest
            
    return grid

def process_one_file(file_path):
    """
    å¤„ç†å•ä¸ª MIDI æ–‡ä»¶ï¼Œè¿”å›å¤šä¸ª segments
    """
    try:
        # åŠ è½½ MIDI
        midi_obj = miditoolkit.MidiFile(file_path)
    except:
        return []

    # 1. æ£€æŸ¥ Time Signatureï¼Œå¦‚æœä¸å« 4/4 æ‹ï¼Œæˆ–è€…å¤ªå¤æ‚ï¼Œè¿™é‡Œç®€å•å¤„ç†ï¼šå¼ºåˆ¶æŒ‰ 4/4 åˆ‡å‰²
    ticks_per_beat = midi_obj.ticks_per_beat
    ticks_per_grid = ticks_per_beat / 2 # 1/8 éŸ³ç¬¦ = 0.5 æ‹
    
    # 2. åˆå¹¶æ‰€æœ‰è½¨é“ (Flatten)
    all_notes = []
    for instrument in midi_obj.instruments:
        if instrument.is_drum: continue # è·³è¿‡é¼“
        all_notes.extend(instrument.notes)
    
    if not all_notes:
        return []

    # æŒ‰æ—¶é—´æ’åº
    all_notes.sort(key=lambda x: x.start)
    
    # è·å–è¿™é¦–æ›²å­çš„æ€»æ—¶é•¿ (ticks)
    max_tick = max(n.end for n in all_notes)
    
    # 3. åˆ‡ç‰‡ (Slicing)
    segments = []
    ticks_per_segment = int(ticks_per_grid * SEQ_LEN)
    
    # æ»‘åŠ¨çª—å£ï¼Œæ­¥é•¿ä¸ºåŠä¸ªç‰‡æ®µï¼ˆOverlap 50%ï¼‰ä»¥å¢åŠ æ•°æ®é‡
    stride = ticks_per_segment // 2 
    
    for start_tick in range(0, max_tick, stride):
        # æå–è¯¥çª—å£å†…çš„éŸ³ç¬¦ (ä¸ºäº† encode_segment æ•ˆç‡ï¼Œè¿™é‡Œå¯ä»¥å…ˆåšç®€å•çš„ filterï¼Œæˆ–è€…æŠŠæ‰€æœ‰ notes ä¼ è¿›å»)
        # è€ƒè™‘åˆ° encode_segment å†…éƒ¨æœ‰åˆ¤æ–­ï¼Œç›´æ¥ä¼ æ‰€æœ‰ notes ç¨å¾®æ…¢ç‚¹ä½†é€»è¾‘ç®€å•
        # ä¸ºäº†æ€§èƒ½ä¼˜åŒ–ï¼Œæˆ‘ä»¬åªä¼ é™„è¿‘çš„ notes
        relevant_notes = [n for n in all_notes if n.end > start_tick and n.start < start_tick + ticks_per_segment]
        
        if not relevant_notes:
            continue

        # ç¼–ç 
        encoded = encode_segment(relevant_notes, ticks_per_grid, start_tick)
        
        # 4. è¿‡æ»¤åƒåœ¾æ•°æ®
        # è§„åˆ™ï¼šå¦‚æœå…¨æ˜¯ä¼‘æ­¢ç¬¦ï¼Œæˆ–è€…éŸ³ç¬¦å¤ªå°‘ï¼ˆæ¯”å¦‚å°‘äº4ä¸ªï¼‰ï¼Œä¸¢å¼ƒ
        # grid > 1 å¯¹åº” pitch (>=2)
        note_count = np.sum(encoded > 1) 
        if note_count < 4: 
            continue
            
        segments.append(encoded)

    # 5. æ•°æ®å¢å¼º (Data Augmentation)
    augmented_segments = []
    for seg in segments:
        for trans in AUGMENT_RANGE:
            # å¤åˆ¶ä¸€ä»½
            aug_seg = seg.copy()
            
            # æ‰¾åˆ° pitch éƒ¨åˆ† (value >= 2)
            pitch_mask = aug_seg >= 2
            
            # ç§»è°ƒ
            aug_seg[pitch_mask] += trans
            
            # æ£€æŸ¥è¾¹ç•Œ
            # MIDI èŒƒå›´ 0-127 -> ç¼–ç èŒƒå›´ 2-129
            # æˆ‘ä»¬é™åˆ¶åœ¨é’¢ç´é”®èŒƒå›´å†… 21-108 -> ç¼–ç  23-110 (å¯é€‰)
            # æˆ–è€…åªè¦ä¸è¶Šç•Œ (0-127) å³å¯
            valid = True
            if np.any(aug_seg[pitch_mask] < 2) or np.any(aug_seg[pitch_mask] > 129):
                valid = False
            
            if valid:
                augmented_segments.append(aug_seg)
                
    return augmented_segments

def main():
    files = glob.glob(os.path.join(INPUT_DIR, "*.mid"))
    files = files[:6000] # å¦‚æœæ–‡ä»¶å¤ªå¤šï¼Œå…ˆæµ‹å‰6000ä¸ª
    print(f"ğŸµ æ‰¾åˆ° {len(files)} ä¸ª MIDI æ–‡ä»¶ï¼Œå‡†å¤‡å¤„ç†...")

    all_data = []
    
    # å¤šè¿›ç¨‹å¤„ç†
    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        results = list(tqdm(executor.map(process_one_file, files), total=len(files)))
    
    # æ±‡æ€»ç»“æœ
    print("ğŸ“¦ æ­£åœ¨åˆå¹¶æ•°æ®...")
    for res in results:
        all_data.extend(res)
    
    # è½¬æ¢ä¸º PyTorch Tensor
    # æ ¼å¼: (N, 32) int64
    print(f"ğŸ“Š åŸå§‹æ•°æ®è½¬æ¢ä¸­... æ€»æ ·æœ¬æ•°: {len(all_data)}")
    if len(all_data) == 0:
        print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥ MIDI æ–‡ä»¶å¤¹è·¯å¾„æˆ–æ–‡ä»¶å†…å®¹ã€‚")
        return

    data_tensor = torch.tensor(np.array(all_data), dtype=torch.long)
    
    # ä¿å­˜
    print(f"ğŸ’¾ ä¿å­˜åˆ° {OUTPUT_FILE} ...")
    torch.save(data_tensor, OUTPUT_FILE)
    
    print("âœ… å®Œæˆï¼")
    print(f"æœ€ç»ˆæ•°æ®é›†å½¢çŠ¶: {data_tensor.shape}")
    print(f"åŒ…å«è¯è¡¨ç´¢å¼•: {data_tensor.min()} ~ {data_tensor.max()}")

if __name__ == "__main__":
    main()