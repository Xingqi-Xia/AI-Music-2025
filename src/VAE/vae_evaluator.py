import torch
import torch.nn.functional as F
import numpy as np
from .train.models import MusicGRUVAE  # ç¡®ä¿ model.py åœ¨åŒä¸€ç›®å½•ä¸‹

class MusicEvaluator:
    def __init__(self, model_path, device=None, config=None):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        :param model_path: è®­ç»ƒå¥½çš„ .pth æ–‡ä»¶è·¯å¾„
        :param device: 'cuda' æˆ– 'cpu'
        :param config: æ¨¡å‹å‚æ•°å­—å…¸ (éœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´)
        """
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        
        # é»˜è®¤é…ç½® (ä¸ä¹‹å‰çš„ train.py ä¿æŒä¸€è‡´)
        self.config = {
            "vocab_size": 130,
            "embed_dim": 256,
            "hidden_dim": 512,
            "latent_dim": 128,
            "seq_len": 32
        }
        if config:
            self.config.update(config)

        # 1. åˆå§‹åŒ–æ¨¡å‹æ¶æ„
        self.model = MusicGRUVAE(
            vocab_size=self.config["vocab_size"],
            embed_dim=self.config["embed_dim"],
            hidden_dim=self.config["hidden_dim"],
            latent_dim=self.config["latent_dim"],
            seq_len=self.config["seq_len"]
        ).to(self.device)

        # 2. åŠ è½½æƒé‡
        print(f"âš–ï¸ æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡: {model_path} ...")
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # å…¼å®¹å¤„ç†ï¼šæ£€æŸ¥æ˜¯ç”¨ save_state_dict ä¿å­˜çš„è¿˜æ˜¯æ•´ä¸ª checkpoint
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
            
        self.model.eval() #ä»¥æ­¤è¿›å…¥è¯„ä¼°æ¨¡å¼ (å…³é—­ Dropout ç­‰)
        
        # ç›®æ ‡é£æ ¼å‘é‡ (åˆå§‹åŒ–ä¸ºç©º)
        self.target_centroid = None
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

    def set_target_style(self, target_data_tensor):
        """
        è®¡ç®—ç›®æ ‡é£æ ¼çš„ä¸­å¿ƒç‚¹ (Latent Centroid)
        :param target_data_tensor: Tensor [N, 32]ï¼ŒåŒ…å«ä½ æƒ³è¦æ¨¡ä»¿çš„ä¹æ›²ç‰‡æ®µ
        """
        print("ğŸ¯ æ­£åœ¨è®¡ç®—ç›®æ ‡é£æ ¼çš„ Latent å‘é‡ä¸­å¿ƒ...")
        target_data_tensor = target_data_tensor.to(self.device)
        
        batch_size = 512
        mus = []
        
        # åˆ†æ‰¹è®¡ç®—ï¼Œé˜²æ­¢æ˜¾å­˜çˆ†ç‚¸
        with torch.no_grad():
            for i in range(0, len(target_data_tensor), batch_size):
                batch = target_data_tensor[i : i + batch_size]
                mu, _ = self.model.encode(batch)
                mus.append(mu)
        
        all_mus = torch.cat(mus, dim=0)
        
        # è®¡ç®—å¹³å‡å‘é‡ (Centroid)
        self.target_centroid = torch.mean(all_mus, dim=0) # [128]
        print(f"âœ… ç›®æ ‡é£æ ¼å·²è®¾å®šã€‚å‚è€ƒæ ·æœ¬æ•°: {len(target_data_tensor)}")

    def get_style_fitness(self, individual_seq):
        """
        æ ¸å¿ƒå‡½æ•°ï¼šè®¡ç®—å•ä¸ªä¸ªä½“çš„é€‚åº”åº¦
        :param individual_seq: list or np.array, é•¿åº¦ä¸º 32 çš„æ•´æ•°åºåˆ—
        :return: float, 0.0 ~ 1.0 (è¶Šé«˜è¶Šå¥½)
        """
        if self.target_centroid is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ set_target_style() è®¾å®šç›®æ ‡é£æ ¼ï¼")

        # é¢„å¤„ç†ï¼šè½¬ä¸º Tensor [1, 32]
        seq_tensor = torch.tensor(individual_seq, dtype=torch.long).unsqueeze(0).to(self.device)

        with torch.no_grad():
            # 1. ç¼–ç å¾—åˆ° latent vector
            mu, _ = self.model.encode(seq_tensor) # [1, 128]
            
            # 2. è®¡ç®—ä¸ç›®æ ‡ä¸­å¿ƒçš„ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
            # ä½™å¼¦ç›¸ä¼¼åº¦èŒƒå›´æ˜¯ [-1, 1]
            similarity = F.cosine_similarity(mu, self.target_centroid.unsqueeze(0))
            
            # 3. å½’ä¸€åŒ–åˆ° [0, 1] æ–¹ä¾¿é—ä¼ ç®—æ³•ä½¿ç”¨
            # sim = 1 -> score = 1
            # sim = -1 -> score = 0
            score = (similarity.item() + 1) / 2
            
        return score

    def evaluate(self, population_grid: np.ndarray) -> np.ndarray:
        """
        æ‰¹é‡æ¥å£ï¼Œé€‚é… GA çš„ evaluator è°ƒç”¨ã€‚
        :param population_grid: numpy æ•°ç»„ï¼Œå½¢çŠ¶ [pop_size, seq_len]
        :return: numpy æ•°ç»„ï¼Œå½¢çŠ¶ [pop_size,]ï¼Œæ¯ä¸ªä¸ªä½“çš„å¾—åˆ† (0~1)
        """
        if self.target_centroid is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ set_target_style() è®¾å®šç›®æ ‡é£æ ¼ï¼")

        # è½¬ Tensor åˆ°æ¨¡å‹è®¾å¤‡ï¼Œä¸€æ¬¡æ€§ç¼–ç å…¨éƒ¨ä¸ªä½“
        pop_tensor = torch.as_tensor(population_grid, dtype=torch.long, device=self.device)
        with torch.no_grad():
            mus, _ = self.model.encode(pop_tensor)  # [B, latent_dim]
            centroid = self.target_centroid.unsqueeze(0)  # [1, latent_dim]
            similarity = F.cosine_similarity(mus, centroid)  # [B]
            scores = torch.clamp((similarity + 1) / 2, min=0.0, max=1.0)  # å½’ä¸€åŒ–åˆ° [0,1]

        return scores.detach().cpu().numpy()

    def get_playability_score(self, individual_seq):
        """
        (å¯é€‰) è®¡ç®—â€œå¯æ¼”å¥æ€§â€æˆ–â€œé€šé¡ºåº¦â€
        åŸç†ï¼šå¦‚æœæ¨¡å‹é‡æ„è¯¯å·®å¾ˆä½ï¼Œè¯´æ˜è¿™æ®µæ—‹å¾‹ç¬¦åˆè®­ç»ƒæ•°æ®çš„è¯­æ³•
        """
        seq_tensor = torch.tensor(individual_seq, dtype=torch.long).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            logits, _, _ = self.model(seq_tensor)
            # ç®€å•çš„ Loss è®¡ç®— (Negative Log Likelihood)
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é”™ä½è®¡ç®—ï¼Œæˆ–è€…ç›´æ¥çœ‹æ¨¡å‹å¯¹å½“å‰åºåˆ—çš„å›°æƒ‘åº¦
            # ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å‡è®¾ loss è¶Šå°è¶Šå¥½ï¼Œè½¬åŒ–æˆ 0~1 åˆ†æ•°
            # è¿™é‡Œçš„å®ç°ç•¥å»å¤æ‚çš„ loss è®¡ç®—ï¼Œä»…ä½œæ¥å£ç¤ºæ„
            pass
        return 0.0

    def repair_melody(self, individual_seq):
        """
        (å¯é€‰) å˜å¼‚æ“ä½œï¼šä¿®å¤æ—‹å¾‹
        å°†æ—‹å¾‹ç¼–ç å†è§£ç ï¼Œå»é™¤ä¸åå’Œçš„å™ªå£°
        """
        seq_tensor = torch.tensor(individual_seq, dtype=torch.long).unsqueeze(0).to(self.device)
        with torch.no_grad():
            mu, _ = self.model.encode(seq_tensor)
            # ä½¿ç”¨å‡å€¼è§£ç  (ä¸åŠ éšæœºå™ªå£°)
            logits = self.model.decode(mu)
            reconstructed = torch.argmax(logits, dim=-1).squeeze(0).cpu().numpy()
        return reconstructed.tolist()